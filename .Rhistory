## Note that the 'n = 20' in the above specifies that a sample of 20 is being taken.
#This is a relatively small number to make things nice and noisy
## Here's a wrapper function that runs the pMax on the 2, 3, 4 and 5 case. To be used later...
p_max_wrapper <- function( correlationSet ){
p1th <- apply(correlationSet, 1, function(x) p_jth(x,1))
p2th <- apply(correlationSet, 1, function(x) p_jth(x,2))
p3th <- apply(correlationSet, 1, function(x) p_jth(x,3))
p4th <- apply(correlationSet, 1, function(x) p_jth(x,4))
p5th <- apply(correlationSet, 1, function(x) p_jth(x,5))
return( data.frame(p2 = p2th, p2 = p2th, p3 = p3th, p4 = p4th, p5 = p5th) )
}
FisherCombProb <- function( pVec ){
testStat = -2*sum(log(pVec))
pVal = 1 - pchisq( testStat, 2*length(pVec) )
return( pVal )
}
pmax <- function(plist,j) {
# get the list of the p-value vector
k=length(plist)
# return an NA if the j parameter is bigger than the length of the p vector
if(j>k) {return(NA)}
# sort the p-values
pjth=sort(plist)[j]
# scale the probabilities
prob = if(j<k) (pjth /sort(plist)[j+1]) else max(plist)
# perform the test
dbinom(x = j, size = j, prob=prob )
}
pmin <- function(plist, j, thresh = 1) {
if (sum( plist < thresh ) == 0 ){
return( NA )
}
# get the list of the p-value vector
k=length(plist) -1
i = j -1
# return an NA if the j parameter is bigger than the length of the p vector
pSort=sort(plist)[2:length(plist)]
if(j>length(plist)) { return(NA) }
if (j-1 == k) {return(max(plist)^k)}
else{
psort = sort(plist)[2:length(plist)]
return((psort[i]/psort[i+1])^(i))
}
}
function_wrapper <- function( correlationSet ){
p_max_p1th <- apply(correlationSet, 1, function(x) pmax(x,1))
p_max_p2th <- apply(correlationSet, 1, function(x) pmax(x,2))
p_max_p3th <- apply(correlationSet, 1, function(x) pmax(x,3))
p_max_p4th <- apply(correlationSet, 1, function(x) pmax(x,4))
p_max_p5th <- apply(correlationSet, 1, function(x) pmax(x,5))
p_min_p2th <- apply(correlationSet, 1, function(x) pmin(x,2))
p_min_p3th <- apply(correlationSet, 1, function(x) pmin(x,3))
p_min_p4th <- apply(correlationSet, 1, function(x) pmin(x,4))
p_min_p5th <- apply(correlationSet, 1, function(x) pmin(x,5))
p_min_p2th_0.01 <- apply(correlationSet, 1, function(x) pmin(x,2, thresh = 0.01))
p_min_p3th_0.01 <- apply(correlationSet, 1, function(x) pmin(x,3, thresh = 0.01))
p_min_p4th_0.01 <- apply(correlationSet, 1, function(x) pmin(x,4,thresh =  0.01))
p_min_p5th_0.01 <- apply(correlationSet, 1, function(x) pmin(x,5,thresh =  0.01))
p_min_p2th_0.05 <- apply(correlationSet, 1, function(x) pmin(x,2,thresh =  0.05))
p_min_p3th_0.05 <- apply(correlationSet, 1, function(x) pmin(x,3, thresh = 0.05))
p_min_p4th_0.05 <- apply(correlationSet, 1, function(x) pmin(x,4,thresh =  0.05))
p_min_p5th_0.05 <- apply(correlationSet, 1, function(x) pmin(x,5, thresh = 0.05))
fisher_pVals <- apply(correlationSet, 1, FisherCombProb)
return( data.frame(p_max_p1 = p_max_p1th,
p_max_p2 = p_max_p2th,
p_max_p3 = p_max_p3th,
p_max_p4 = p_max_p4th,
p_max_p5 = p_max_p5th,
p_min_p2 = p_min_p2th,
p_min_p3 = p_min_p3th,
p_min_p4 = p_min_p4th,
p_min_p5 = p_min_p5th,
p_min_p2_0.01 = p_min_p2th_0.01,
p_min_p3_0.01 = p_min_p3th_0.01,
p_min_p4_0.01 = p_min_p4th_0.01,
p_min_p5_0.01 = p_min_p5th_0.01,
p_min_p2_0.05 = p_min_p2th_0.05,
p_min_p3_0.05 = p_min_p3th_0.05,
p_min_p4_0.05 = p_min_p4th_0.05,
p_min_p5_0.05 = p_min_p5th_0.05,
FisherPVal = fisher_pVals) )
}
cor = 0.0
plotHistograms<-function(cor){
## Let's start with a case with no correlation (10000 replicates)
## The vector of zeroes is the population correlation for each "species"
noCorrelationSet <- simulateMultipleGEAs( c(0.0, 0.0, 0.0, 0.0, 0.0), 100)
oneoHitSet <- simulateMultipleGEAs( c(cor, 0.0, 0.0, 0.0, 0.0), 100)
twoHitSet <- simulateMultipleGEAs( c(cor, cor, 0.0, 0.0, 0.0), 100)
threeHitSet <- simulateMultipleGEAs( c(cor, cor, cor, 0.0, 0.0), 100)
fourHitSet <- simulateMultipleGEAs( c(cor, cor, cor, cor, 0.0), 100)
fiveHitSet <- simulateMultipleGEAs( c(cor, cor, cor, cor, cor), 100)
noCor <- function_wrapper( noCorrelationSet )
noCor_pMax <- apply( noCor[,1:5], 1, p_value_adjustment )
noCor_pMin <- apply( noCor[,6:9], 1, p_value_adjustment )
noCor_pMin_0.01 <- apply( noCor[,10:13], 1, p_value_adjustment )
noCor_pMin_0.05 <- apply( noCor[,14:17], 1, p_value_adjustment )
sum( na.omit(noCor_pMin_0.01) < 0.05 )
par(mfrow = c(6,5))
hist( noCor_pMax ,
main = "No hits\npMax",
xlab = "Nop-value")
hist( noCor_pMin ,
main = "No hits\npMin",
xlab = "p-value")
hist( noCor_pMin_0.01 ,
main = "No hits\npMin - 0.01 threshold",
xlab = "p-value")
hist( noCor_pMin_0.05 ,
main = "No hits\npMin - 0.05 threshold",
xlab = "p-value")
hist( noCor$FisherPVal ,
main = "No hits\nFisher's Combined Probality",
xlab = "p-value")
oneCor <- function_wrapper( oneoHitSet )
oneCor_pMax <- apply( oneCor[,1:5], 1, p_value_adjustment )
oneCor_pMin <- apply( oneCor[,6:9], 1, p_value_adjustment )
oneCor_pMin_0.01 <- apply( oneCor[,10:13], 1, p_value_adjustment )
oneCor_pMin_0.05 <- apply( oneCor[,14:17], 1, p_value_adjustment )
hist( oneCor_pMax ,
main = "One hits\npMax",
xlab = "p-value")
hist( oneCor_pMin ,
main = "One hits\npMin",
xlab = "p-value")
hist( oneCor_pMin_0.01 ,
main = "One hits\npMin - 0.01 threshold",
xlab = "p-value")
hist( oneCor_pMin_0.05 ,
main = "One hits\npMin - 0.05 threshold",
xlab = "p-value")
hist( oneCor$FisherPVal ,
main = "One hits\nFisher's Combined Probality",
xlab = "p-value")
twoCor <- function_wrapper( twoHitSet )
twoHitSet_pMax <- apply( twoCor[,1:5], 1, p_value_adjustment )
twoHitSet_pMin <- apply( twoCor[,6:9], 1, p_value_adjustment )
twoHitSet_pMin_0.01 <- apply( twoCor[,10:13], 1, p_value_adjustment )
twoHitSet_pMin_0.05 <- apply( twoCor[,14:17], 1, p_value_adjustment )
hist( twoHitSet_pMax ,
main = "Two hits\npMax",
xlab = "p-value")
hist( twoHitSet_pMin ,
main = "Two hits\npMin",
xlab = "p-value")
hist( twoHitSet_pMin_0.01 ,
main = "Two hits\npMin - 0.01 threshold",
xlab = "p-value")
hist( twoHitSet_pMin_0.05 ,
main = "Two hits\npMin - 0.05 threshold",
xlab = "p-value")
hist( twoCor$FisherPVal ,
main = "Two hits\nFisher's Combined Probality",
xlab = "p-value")
threeCor <- function_wrapper( threeHitSet )
threeHitSet_pMax <- apply( threeCor[,1:5], 1, p_value_adjustment )
threeHitSet_pMin <- apply( threeCor[,6:9], 1, p_value_adjustment )
threeHitSet_pMin_0.01 <- apply( threeCor[,10:13], 1, p_value_adjustment )
threeHitSet_pMin_0.05 <- apply( threeCor[,14:17], 1, p_value_adjustment )
hist( threeHitSet_pMax ,
main = "Three hits\npMax",
xlab = "p-value")
hist( threeHitSet_pMin ,
main = "Three hits\npMin",
xlab = "p-value")
hist( threeHitSet_pMin_0.01 ,
main = "Three hits\npMin - 0.01 threshold",
xlab = "p-value")
hist( threeHitSet_pMin_0.05 ,
main = "Three hits\npMin - 0.05 threshold",
xlab = "p-value")
hist( threeCor$FisherPVal ,
main = "Three hits\nFisher's Combined Probality",
xlab = "p-value")
fourCor <- function_wrapper( fourHitSet )
fourHitSet_pMax <- apply( fourCor[,1:5], 1, p_value_adjustment )
fourHitSet_pMin <- apply( fourCor[,6:9], 1, p_value_adjustment )
fourHitSet_pMin_0.01 <- apply( fourCor[,10:13], 1, p_value_adjustment )
fourHitSet_pMin_0.05 <- apply( fourCor[,14:17], 1, p_value_adjustment )
hist( fourHitSet_pMax ,
main = "Four hits\npMax",
xlab = "p-value")
hist( fourHitSet_pMin ,
main = "Four hits\npMin",
xlab = "p-value")
hist( fourHitSet_pMin_0.01 ,
main = "Four hits\npMin - 0.01 threshold",
xlab = "p-value")
hist( fourHitSet_pMin_0.05 ,
main = "Four hits\npMin - 0.05 threshold",
xlab = "p-value")
hist( fourCor$FisherPVal ,
main = "Four hits\nFisher's Combined Probality",
xlab = "p-value")
fiveCor <- function_wrapper( fiveHitSet )
fiveHitSet_pMax <- apply( fiveCor[,1:5], 1, p_value_adjustment )
fiveHitSet_pMin <- apply( fiveCor[,6:9], 1, p_value_adjustment )
fiveHitSet_pMin_0.01 <- apply( fiveCor[,10:13], 1, p_value_adjustment )
fiveHitSet_pMin_0.05 <- apply( fiveCor[,14:17], 1, p_value_adjustment )
hist( fiveHitSet_pMax ,
main = "Five hits\npMax",
xlab = "p-value")
hist( fiveHitSet_pMin ,
main = "Five hits\npMin",
xlab = "p-value")
hist( fiveHitSet_pMin_0.01 ,
main = "Five hits\npMin - 0.01 threshold",
xlab = "p-value")
hist( fiveHitSet_pMin_0.05 ,
main = "Five hits\npMin - 0.05 threshold",
xlab = "p-value")
hist( fiveCor$FisherPVal ,
main = "Five hits\nFisher's Combined Probality",
xlab = "p-value")
}
pdf("powerHistograms.pdf", height = 20, width = 10)
for (i in 0:6){
plotHistograms(i/10)
}
dev.off()
getMinIndex <- function(x){
if (anyNA(x)){
return(NA)
}
else{
c(2,3,4,5)[which.min(x)]
}
}
numHits = 4
cor = 0.4
numReps = 100
getPowerFunc <-function(cor, numHits, numReps){
## Let's start with a case with no correlation (10000 replicates)
## The vector of zeroes is the population correlation for each "species"
species_correlation_vector <- c( rep(cor, numHits), rep(0, 5-numHits))
HitSet <- simulateMultipleGEAs( species_correlation_vector, numReps)
Cor <- function_wrapper( HitSet )
Cor_pMax <- apply( Cor[,1:5], 1, p_value_adjustment )
Cor_pMin <- apply( Cor[,6:9], 1, p_value_adjustment )
Cor_pMin_0.01 <- apply( Cor[,10:13], 1, p_value_adjustment )
Cor_pMin_0.05 <- apply( Cor[,14:17], 1, p_value_adjustment )
Cor_pMax_num <- apply( Cor[,1:5], 1, getMinIndex )
Cor_pMin_num <- apply( Cor[,6:9], 1, getMinIndex )
Cor_pMin_0.01_num <- apply( Cor[,10:13], 1, getMinIndex )
Cor_pMin_0.05_num <- apply( Cor[,14:17], 1, getMinIndex )
Cor_DF_entry <- c(numHits, ##The number of true positives
cor, # The correlation with the env
sum(Cor_pMax < 0.05)/numReps,
sum(na.omit(Cor_pMin) < 0.05)/numReps,
sum(na.omit(Cor_pMin_0.01) < 0.05)/numReps,
sum(na.omit(Cor_pMin_0.05) < 0.05)/numReps,
sum(Cor$FisherPVal < 0.05)/numReps,
sum(na.omit(Cor_pMax_num) == numHits )/length(na.omit(Cor_pMax_num)),
sum(na.omit(Cor_pMin_num) == numHits )/length(na.omit(Cor_pMin_num)),
sum(na.omit(Cor_pMin_0.01_num) == numHits )/length(na.omit(Cor_pMin_0.01_num)),
sum(na.omit(Cor_pMin_0.05_num) == numHits )/length(na.omit(Cor_pMin_0.05_num))
)
return(Cor_DF_entry)
}
count = 0
results = list()
for (i in c(0.05, 1:6/10)){
for  (j in c(0:5)){
count = count + 1
results[[count]] = getPowerFunc(numReps = 5000, numHits = j, cor = i)
}
}
powerDF <- data.frame( do.call(rbind, results) )
names(powerDF) <- c("numHits",
"cor",
"pMax",
"pMin",
"pMin_thresh_0.01",
"pMin_thresh_0.05",
"Fisher",
"pMax_ID",
"pMin_ID",
"pMin_thresh_0.01_ID",
"pMin_thresh_0.05_ID")
library(ggplot2)
library(reshape2)
meltedDF <- melt(powerDF, id = c("numHits",
"cor",
"pMax_ID",
"pMin_ID",
"pMin_thresh_0.01_ID",
"pMin_thresh_0.05_ID"))
library(PNWColors)
pal <- pnw_palette("Sunset2", 6)
ggplot(data=meltedDF, aes( x = cor, y = value, col = as.factor(numHits)) )+
facet_wrap(~variable, nrow= 1)+
ggtitle("Power to identify adaptation (by number of hits)")+
scale_y_continuous("Power")+
scale_x_continuous("Correlation coefficient")+
geom_line(lwd = 1)+
scale_color_manual("Number of\nTrue Positives", values =  pnw_palette("Sunset2", 6))+
theme_bw()
ggplot(data=meltedDF, aes( x = cor, y = value, col = variable ) )+
facet_wrap(~as.factor(numHits), nrow= 1)+
ggtitle("Power to identify adaptation (by test)")+
scale_y_continuous("Power")+
scale_x_continuous("Correlation coefficient")+
geom_line(lwd = 1)+
scale_color_manual("Test", values =  pnw_palette("Sunset2", 5))+
theme_bw()
meltedDF_ID <- melt(powerDF, id = c("numHits",
"cor",
"pMax",
"pMin",
"pMin_thresh_0.01",
"pMin_thresh_0.05",
"Fisher"))
ggplot(data=meltedDF_ID[meltedDF_ID$numHits>1,], aes( x = cor, y = value, col = variable ) )+
facet_wrap(~as.factor(numHits), nrow= 1)+
ggtitle("Power to determine the convergence configuration (by number of hits)")+
geom_hline(aes(yintercept = 0.25),)+
scale_y_continuous("Power")+
scale_x_continuous("Correlation coefficient")+
scale_color_manual("Test", values =  pnw_palette("Sunset2", 5))+
geom_line(lwd = 1)+
theme_bw()
ggplot(data=meltedDF_ID[meltedDF_ID$numHits>1,], aes( x = cor, y = value, col = as.factor(numHits)) )+
facet_wrap(~variable, nrow= 1)+
ggtitle("Power to determine the convergence configuration (by test)")+
geom_hline(aes(yintercept = 0.25),)+
scale_y_continuous("Power")+
scale_x_continuous("Correlation coefficient")+
scale_color_manual("Number of Hits", values =  pnw_palette("Sunset2", 5))+
geom_line(lwd = 1)+
theme_bw()
pVec <- c(0.1,0.2,0.3)
## Make some number line plots for talks etc.
## Null hypothesis
pVec <- data.frame( pval = c(simulateMultipleGEAs( c(0,0,0,0,0), 1)),
species = 1:5)
pVec_melted <- melt(pVec, id = "species")
noSpeciesPlot<- ggplot(pVec_melted)+
geom_vline( aes( xintercept = value, color = as.factor(species)),
lwd = 2)+
ggtitle(expression(bold("All species satisfy the null hypothesis")))+
scale_x_continuous(expression(italic(p)*"-value"),
limits = c(0,1),
breaks = c(0,1),
expand = c(0,0))+
scale_color_manual(values = pal)+
guides(colour = F)+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(face= "bold", size = 12),
plot.title = element_text(face= "bold", size = 12, hjust = 0.5),
axis.title.x = element_text(face= "bold", size = 12))
pdf("noSpeciesPlot.pdf",height= 2,width = 5)
print(noSpeciesPlot)
dev.off()
## One false hypothesis
pVec <- data.frame( pval = c(simulateMultipleGEAs( c(0.4, 0, 0, 0, 0), 1)),
species = 1:5)
pVec_melted <- melt(pVec, id = "species")
oneSpeciesPlot<- ggplot(pVec_melted)+
geom_vline( aes( xintercept = value, color = as.factor(species)),
lwd = 2)+
ggtitle(expression(bold("One species has a false null hypothesis ("*italic(r)*" = 0.4)")))+
scale_x_continuous(expression(italic(p)*"-value"),
limits = c(0,1),
breaks = c(0,1),
expand = c(0,0))+
scale_color_manual(values = pal)+
guides(colour = F)+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(face= "bold", size = 12),
plot.title = element_text(face= "bold", size = 12, hjust = 0.5),
axis.title.x = element_text(face= "bold", size = 12))
pdf("oneSpeciesPlot.pdf",height= 2,width = 5)
print(oneSpeciesPlot)
dev.off()
## Two false hypothesis
pVec <- data.frame( pval = c(simulateMultipleGEAs( c(0.4, 0.4, 0, 0, 0), 1)),
species = 1:5)
pVec_melted <- melt(pVec, id = "species")
twoSpeciesPlot<- ggplot(pVec_melted)+
geom_vline( aes( xintercept = value, color = as.factor(species)),
lwd = 2)+
ggtitle(expression(bold("Two species have a false null hypothesis ("*italic(r)*" = 0.4)")))+
scale_x_continuous(expression(italic(p)*"-value"),
limits = c(0,1),
breaks = c(0,1),
expand = c(0,0))+
scale_color_manual(values = pal)+
guides(colour = F)+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(face= "bold", size = 12),
plot.title = element_text(face= "bold", size = 12, hjust = 0.5),
axis.title.x = element_text(face= "bold", size = 12))
pdf("twoSpeciesPlot.pdf",height= 2,width = 5)
print(twoSpeciesPlot)
dev.off()
## Three false nulls
pVec <- data.frame( pval = c(simulateMultipleGEAs( c(0.4, 0.4, 0.4, 0, 0), 1)),
species = 1:5)
pVec_melted <- melt(pVec, id = "species")
threeSpeciesPlot<- ggplot(pVec_melted)+
geom_vline( aes( xintercept = value, color = as.factor(species)),
lwd = 2)+
ggtitle(expression(bold("Three species have a false null hypothesis ("*italic(r)*" = 0.4)")))+
scale_x_continuous(expression(italic(p)*"-value"),
limits = c(0,1),
breaks = c(0,1),
expand = c(0,0))+
scale_color_manual(values = pal)+
guides(colour = F)+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(face= "bold", size = 12),
plot.title = element_text(face= "bold", size = 12, hjust = 0.5),
axis.title.x = element_text(face= "bold", size = 12))
pdf("threeSpeciesPlot.pdf",height= 2,width = 5)
print(threeSpeciesPlot)
dev.off()
## Four false nulls
pVec <- data.frame( pval = c(simulateMultipleGEAs( c(0.4, 0.4, 0.4, 0.4, 0), 1)),
species = 1:5)
pVec_melted <- melt(pVec, id = "species")
fourSpeciesPlot<- ggplot(pVec_melted)+
geom_vline( aes( xintercept = value, color = as.factor(species)),
lwd = 2)+
ggtitle(expression(bold("Four species have a false null hypothesis ("*italic(r)*" = 0.4)")))+
scale_x_continuous(expression(italic(p)*"-value"),
limits = c(0,1),
breaks = c(0,1),
expand = c(0,0))+
scale_color_manual(values = pal)+
guides(colour = F)+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(face= "bold", size = 12),
plot.title = element_text(face= "bold", size = 12, hjust = 0.5),
axis.title.x = element_text(face= "bold", size = 12))
pdf("fourSpeciesPlot.pdf",height= 2,width = 5)
print(fourSpeciesPlot)
dev.off()
## Five false nulls
pVec <- data.frame( pval = c(simulateMultipleGEAs( c(0.4, 0.4, 0.4, 0.4, 0.4), 1)),
species = 1:5)
pVec_melted <- melt(pVec, id = "species")
fiveSpeciesPlot<- ggplot(pVec_melted)+
geom_vline( aes( xintercept = value, color = as.factor(species)),
lwd = 2)+
ggtitle(expression(bold("Five species have a false null hypothesis ("*italic(r)*" = 0.4)")))+
scale_x_continuous(expression(italic(p)*"-value"),
limits = c(0,1),
breaks = c(0,1),
expand = c(0,0))+
scale_color_manual(values = pal)+
guides(colour = F)+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(face= "bold", size = 12),
plot.title = element_text(face= "bold", size = 12, hjust = 0.5),
axis.title.x = element_text(face= "bold", size = 12))
pdf("fiveSpeciesPlot.pdf",height= 2,width = 5)
print(fiveSpeciesPlot)
dev.off()
cor = 0.3
noCorrelationSet <- simulateMultipleGEAs( c(0.0, 0.0, 0.0, 0.0, 0.0), 100)
oneoHitSet <- simulateMultipleGEAs( c(cor, 0.0, 0.0, 0.0, 0.0), 100)
twoHitSet <- simulateMultipleGEAs( c(cor, cor, 0.0, 0.0, 0.0), 100)
threeHitSet <- simulateMultipleGEAs( c(cor, cor, cor, 0.0, 0.0), 100)
fourHitSet <- simulateMultipleGEAs( c(cor, cor, cor, cor, 0.0), 100)
fiveHitSet <- simulateMultipleGEAs( c(cor, cor, cor, cor, cor), 100)
oneoHitSet <- simulateMultipleGEAs( c(cor, 0.0, 0.0, 0.0, 0.0), 1)
p_VEC <- c(.300139593, 0.004070485, 0.3231278620, 0.9332333729, 0.0278269275 )
FisherCombProb(p_VEC)
pmin_vec <- c(pmax(p_VEC,1),
pmax(p_VEC,2),
pmax(p_VEC,3),
pmax(p_VEC,4),
pmax(p_VEC,5))
1- (1-min(pmin_vec))^5
0.00407/0.02782
oneoHitSet <- simulateMultipleGEAs( c(0.3, 0.2, 0.3, 0.3, 0.0), 1000)
p_max_wrapper_2 <- function( pVec ){
pmax_vec <- c( pmax( pVec , 1),
pmax( pVec , 2),
pmax( pVec , 3),
pmax( pVec , 4),
pmax( pVec , 5))
return( p_value_adjustment(pmax_vec))
}
Fisher_hitters <- apply(oneoHitSet,1, FisherCombProb)
pmax_hitters <- apply(oneoHitSet,1, p_max_wrapper_2)
sum(Fisher_hitters<0.05)
sum(pmax_hitters<0.05)
